{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import utils, transforms\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "from siamese_script import resnet101, normalize_data\n",
    "import pickle\n",
    "# import horovod.torch as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample duration 218\n",
      "last duration 12\n",
      "Last size 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet101()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    checkpoint = torch.load(f'/nethome/asilva9/brains/model_checkpoints/siamese_final.pth.tar')\n",
    "else:\n",
    "    checkpoint = torch.load(f'/nethome/asilva9/brains/model_checkpoints/siamese_final.pth.tar', map_location='cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedNIFTIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    create a dataset class in PyTorch for reading NIfTI files\n",
    "    Args:\n",
    "        source_dir (str): path to images\n",
    "        transform (Callable): transform to apply to images (Probably None or ToTensor)\n",
    "        preload (bool): load all data when initializing the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_fns = np.loadtxt(data_path, delimiter=',')\n",
    "        self.transform = transform\n",
    "        self.data_len = len(self.data_fns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vol_in = self.data_fns[idx]\n",
    "        main_vol = nib.load(vol_in).get_fdata(dtype=np.float32)\n",
    "        main_vol = np.moveaxis(main_vol, 1, 0)\n",
    "        sample = main_vol\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample).unsqueeze(0)\n",
    "        return sample\n",
    "\n",
    "pos_dataset = EmbedNIFTIDataset(data_dir='/media/data/Track_2/good',\n",
    "                             label=1,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "neg_dataset = EmbedNIFTIDataset(data_dir=\"/media/data/Track_2/bad\",\n",
    "                                label=0,\n",
    "                                transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_loader = torch.utils.data.DataLoader(pos_dataset, batch_size=1)\n",
    "neg_loader = torch.utils.data.DataLoader(neg_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = []\n",
    "labels = []\n",
    "for i, data in enumerate(pos_loader):\n",
    "    img, label = data\n",
    "    if use_gpu:\n",
    "        img = img.cuda()\n",
    "    img = normalize_data(img)\n",
    "    output = model.get_embed(img)\n",
    "    embeds.append(output.detach().cpu().numpy().reshape(-1))\n",
    "    labels.append(label.item())\n",
    "for i, data in enumerate(neg_loader):\n",
    "    img, label = data\n",
    "    if use_gpu:\n",
    "        img = img.cuda()\n",
    "    img = normalize_data(img)\n",
    "    output = model.get_embed(img)\n",
    "    embeds.append(output.detach().cpu().numpy().reshape(-1))\n",
    "    labels.append(label.item())\n",
    "\n",
    "np.savetxt('embeds.csv', np.array(embeds), delimiter=',', newline='\\n')\n",
    "np.savetxt('labels.csv', np.array(labels), delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data_path='', model_path='./siamese_final.pth.tar' data_name='all', use_gpu=True):\n",
    "    dataset = EmbedNIFTIDataset(data_path=data_path,\n",
    "                                label=0,\n",
    "                                transform=transforms.ToTensor())\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "    model = resnet101()\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "        checkpoint = torch.load(model_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    embeds = []\n",
    "    for i, data in enumerate(data_loader):\n",
    "        img = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "        img = normalize_data(img)\n",
    "        output = model.get_embed(img)\n",
    "        embeds.append(output.detach().cpu().numpy().reshape(-1))\n",
    "    np.savetxt(data_name+'embeds.csv', np.array(embeds), delimiter=',', newline='\\n')\n",
    "    return np.array(embeds)\n",
    "\n",
    "def generate_labels(data_dir='/media/data/Track_2', data_name='all'):\n",
    "    dataset = EmbedNIFTIDataset(data_dir=data_dir, label=0, transform=transforms.ToTensor())\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    labels = []\n",
    "    for i, data in enumerate(data_loader):\n",
    "        img, label = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "        img = normalize_data(img)\n",
    "        output = model([img])[0]\n",
    "        output = F.softmax(output, dim=1)\n",
    "        labels.append(1-output[0][0].item())\n",
    "    np.savetxt(data_name+'_pred_labels.csv', np.array(labels), delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_labels(data_dir='/media/data/Track_2/good', data_name='good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_labels(data_dir='/media/data/Track_2/bad', data_name='bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
