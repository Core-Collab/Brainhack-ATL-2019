{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from functools import partial\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import utils, transforms\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "from torch import optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterNIFTIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    create a dataset class in PyTorch for reading NIfTI files\n",
    "    Args:\n",
    "        source_dir (str): path to images\n",
    "        transform (Callable): transform to apply to images (Probably None or ToTensor)\n",
    "        preload (bool): load all data when initializing the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, positive_dir, negative_dir, transform=None):\n",
    "        self.pos_fns = sorted(glob(os.path.join(positive_dir, \"*.nii.gz\")))\n",
    "        self.neg_fns = sorted(glob(os.path.join(negative_dir, \"*.nii.gz\")))\n",
    "        self.transform = transform\n",
    "        self.pos_len = len(self.pos_fns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.pos_len+len(self.neg_fns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        neg_img = False\n",
    "        if idx >= self.pos_len:\n",
    "            neg_img = True\n",
    "            idx -= self.pos_len\n",
    "            vol_in = self.neg_fns[idx]\n",
    "        else:\n",
    "            vol_in = self.pos_fns[idx]\n",
    "\n",
    "        same_class = random.randint(0,1)\n",
    "        if (same_class and neg_img) or (not same_class and not neg_img):\n",
    "            fn = random.choice(self.neg_fns)\n",
    "        elif (same_class and not neg_img) or (not same_class and neg_img):\n",
    "            fn = random.choice(self.pos_fns)\n",
    "        main_vol = nib.load(vol_in).get_fdata(dtype=np.float32)\n",
    "        partner_vol = nib.load(fn).get_fdata(dtype=np.float32)\n",
    "        main_vol = np.moveaxis(main_vol, 1, 0)\n",
    "        partner_vol = np.moveaxis(partner_vol, 1, 0)\n",
    "        sample = [main_vol, partner_vol]\n",
    "        if self.transform is not None:\n",
    "            sample = [self.transform(sample[0]).unsqueeze(0), self.transform(sample[1]).unsqueeze(0)]\n",
    "        if same_class:\n",
    "            sample.append(torch.Tensor([0]))\n",
    "        else:\n",
    "            sample.append(torch.Tensor([1]))\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    # 3x3x3 convolution with padding\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        bias=False)\n",
    "\n",
    "\n",
    "def downsample_basic_block(x, planes, stride):\n",
    "    out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "    zero_pads = torch.Tensor(\n",
    "        out.size(0), planes - out.size(1), out.size(2), out.size(3),\n",
    "        out.size(4)).zero_()\n",
    "    if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "        zero_pads = zero_pads.cuda()\n",
    "\n",
    "    out = Variable(torch.cat([out.data, zero_pads], dim=1))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "class ResNeXtBottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, cardinality, stride=1,\n",
    "                 downsample=None):\n",
    "        super(ResNeXtBottleneck, self).__init__()\n",
    "        mid_planes = cardinality * int(planes / 32)\n",
    "        self.conv1 = nn.Conv3d(inplanes, mid_planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(mid_planes)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            mid_planes,\n",
    "            mid_planes,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            groups=cardinality,\n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(mid_planes)\n",
    "        self.conv3 = nn.Conv3d(\n",
    "            mid_planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNeXt(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layers,\n",
    "                 sample_size,\n",
    "                 sample_duration,\n",
    "                 shortcut_type='B',\n",
    "                 cardinality=32,\n",
    "                 num_classes=400):\n",
    "        self.inplanes = 64\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            1,\n",
    "            64,\n",
    "            kernel_size=7,\n",
    "            stride=(1, 2, 2),\n",
    "            padding=(3, 3, 3),\n",
    "            bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[0], shortcut_type,\n",
    "                                       cardinality)\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, 256, layers[1], shortcut_type, cardinality, stride=2)\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, 512, layers[2], shortcut_type, cardinality, stride=2)\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, 1024, layers[3], shortcut_type, cardinality, stride=2)\n",
    "        print(\"sample duration\", sample_duration)\n",
    "        last_duration = int(math.ceil(sample_duration / 19))  # hacked?\n",
    "        print(\"last duration\", last_duration)\n",
    "        last_size = int(math.ceil(sample_size / 32))\n",
    "        print(\"Last size\", last_size)\n",
    "        self.avgpool = nn.AvgPool3d(\n",
    "            (last_duration, last_size+1, last_size), stride=1)  # hacked also\n",
    "        self.fc = nn.Linear(cardinality * 32 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                m.weight = nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self,\n",
    "                    block,\n",
    "                    planes,\n",
    "                    blocks,\n",
    "                    shortcut_type,\n",
    "                    cardinality,\n",
    "                    stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(\n",
    "                    downsample_basic_block,\n",
    "                    planes=planes * block.expansion,\n",
    "                    stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        self.inplanes,\n",
    "                        planes * block.expansion,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False), nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, cardinality, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, cardinality))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def model_pass(self, data_in):\n",
    "        data_in = self.conv1(data_in)\n",
    "        data_in = self.bn1(data_in)\n",
    "        data_in = self.relu(data_in)\n",
    "        data_in = self.maxpool(data_in)\n",
    "        data_in = self.layer1(data_in)\n",
    "        data_in = self.layer2(data_in)\n",
    "        data_in = self.layer3(data_in)\n",
    "        data_in = self.layer4(data_in)\n",
    "        data_in = self.avgpool(data_in)\n",
    "        data_in = data_in.view(data_in.size(0), -1)\n",
    "        data_in = self.fc(data_in)\n",
    "\n",
    "        return data_in\n",
    "    \n",
    "    def forward(self, x_arr_in):\n",
    "        labels = []\n",
    "        for sample in x_arr_in:\n",
    "            labels.append(self.model_pass(sample))\n",
    "        return labels\n",
    "\n",
    "\n",
    "def get_fine_tuning_parameters(model, ft_begin_index):\n",
    "    if ft_begin_index == 0:\n",
    "        return model.parameters()\n",
    "\n",
    "    ft_module_names = []\n",
    "    for i in range(ft_begin_index, 5):\n",
    "        ft_module_names.append('layer{}'.format(i))\n",
    "    ft_module_names.append('fc')\n",
    "\n",
    "    parameters = []\n",
    "    for k, v in model.named_parameters():\n",
    "        for ft_module in ft_module_names:\n",
    "            if ft_module in k:\n",
    "                parameters.append({'params': v})\n",
    "                break\n",
    "        else:\n",
    "            parameters.append({'params': v, 'lr': 0.0})\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNeXt(ResNeXtBottleneck, [3, 4, 6, 3], \n",
    "                    num_classes=2,\n",
    "                    shortcut_type='B',\n",
    "                    cardinality=32,\n",
    "                    sample_size=182,\n",
    "                    sample_duration=218)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNeXt(ResNeXtBottleneck, [3, 4, 23, 3], \n",
    "                    num_classes=2,\n",
    "                    shortcut_type='B',\n",
    "                    cardinality=32,\n",
    "                    sample_size=182,\n",
    "                    sample_duration=218)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important functions\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig('loss_fig.png')\n",
    "    plt.show()\n",
    "\n",
    "def normalize_data(images_batch):\n",
    "    mean_val = images_batch.mean(dim=[2,3,4])\n",
    "    std_val = images_batch.std(dim=[2,3,4])\n",
    "    images_batch = (images_batch-mean_val[:, :, None, None, None])/std_val[:, :, None, None, None]\n",
    "    return images_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "pos_fns = sorted(glob(os.path.join('/media/data/Track_2/good', \"*.nii.gz\")))\n",
    "neg_fns = sorted(glob(os.path.join('/media/data/Track_2/bad', \"*.nii.gz\")))\n",
    "validation_split = .1\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "pos_size = len(pos_fns) + len(neg_fns)\n",
    "indices = list(range(pos_size))\n",
    "split = int(np.floor(validation_split * pos_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet101().cuda()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.1)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "counter = []\n",
    "loss_history = []\n",
    "train_epochs = 5\n",
    "iteration_number= 0\n",
    "dataset = MasterNIFTIDataset(positive_dir='/media/data/Track_2/good',\n",
    "                               negative_dir='/media/data/Track_2/bad',\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the dataloader\n",
    "# def imshow(img,text=None,should_save=False):\n",
    "#     npimg = img.numpy()\n",
    "#     plt.axis(\"off\")\n",
    "#     if text:\n",
    "#         plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "#             bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()    \n",
    "\n",
    "# dataiter = iter(dataloader)\n",
    "\n",
    "\n",
    "# example_batch = next(dataiter)\n",
    "# example_batch[0] = normalize_data(example_batch[0])\n",
    "# example_batch[1] = normalize_data(example_batch[1])\n",
    "# image_one = example_batch[0][:, :, 50, :, :]\n",
    "# image_two = example_batch[1][:, :, 50, :, :]\n",
    "# concatenated = torch.cat((image_one,image_two),0)\n",
    "# imshow(utils.make_grid(concatenated))\n",
    "# print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(train_epochs):\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        img0, img1 , label = data\n",
    "        img0 = normalize_data(img0)\n",
    "        img1 = normalize_data(img1)\n",
    "        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = net([img0,img1])\n",
    "        loss_contrastive = criterion(output1,output2,label)\n",
    "        if np.isnan(loss_contrastive.item()):\n",
    "            continue\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i %100 == 0 :\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "            break\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss_history,\n",
    "            }, f'/nethome/asilva9/brains/model_checkpoints/siamese_epoch{epoch}.pth.tar')\n",
    "    sim_loss = 0\n",
    "    diff_loss = 0\n",
    "    for i, data in enumerate(validation_loader, 0):\n",
    "        img0, img1 , label = data\n",
    "        img0 = normalize_data(img0)\n",
    "        img1 = normalize_data(img1)\n",
    "        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
    "        output1,output2 = net([img0,img1])\n",
    "        loss_contrastive = criterion(output1,output2,label)\n",
    "        if label > 0:\n",
    "            diff_loss += loss_contrastive.item()\n",
    "        else:\n",
    "            sim_loss += loss_contrastive.item()\n",
    "    print(f\"Diff loss: {diff_loss}\")\n",
    "    print(f\"Sim loss: {sim_loss}\")\n",
    "        \n",
    "show_plot(counter,loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
